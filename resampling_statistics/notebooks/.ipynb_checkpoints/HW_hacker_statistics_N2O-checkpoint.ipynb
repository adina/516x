{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework for hacker / resampling-based statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "Now you have a good understanding about 1) what is hacker statistics / resampling based statistical inferences, 2) how to estimate the confidence intervals for given parameters using Bootstrap, and 3) how to compare statistics of two populations with permutation test. It's time to apply these knowledge to the real world problems!  \n",
    "\n",
    "<br>\n",
    "\n",
    "Here you will be working with per capita nitrous oxide emission data from the United States from 1990 to 2016. As we may know, green house gas emission, such as carbon dioxide (CO2), is a big environmental issue. Less well known as CO2, nitrous oxide (N2O), contributing to around $6\\%$ of the overall green house gas emission, has becoming a recent environmental concern. In this assignment, you will focus on studying the per capita N2O emission of the United States before and after year 2015. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks:\n",
    "\n",
    "- Go through and run the cells in **Step 1** to pre-process the N2O data you are gonna use in the later sections\n",
    "\n",
    "- Finish **Question 1** and **Question 2** following the instructions\n",
    "\n",
    "- Use the lecture notebook as your reference if needed\n",
    "\n",
    "## Note:\n",
    "\n",
    "All the functions you created in the lecture exercises that generate Bootstrap or Permutation samples, replicates, or test statistic (`bs_replicate_1d`; `draw_bs_reps`; `permutation_sample`, `draw_permutation_reps`, `mean_diff`) are collected into the `hast` module. This module will be loaded for you in **Step 1**. Later you can call these functions in `hast` just like how you would call functions from any other modules, such as `numpy`, for instance, use `hast.draw_bs_reps(...)` to draw Bootstrap replicates. You can also get the documentation information of each function just like how you would do with any other functions, for example, get the usage information of `hast.mean_diff` function by `help(hast.mean_diff)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Read in and pre-processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Install packages**  \n",
    "\n",
    "First, let's install the packages that will be used to analyze the per capita nitrous oxide emissions data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **Read in the nitrous oxide emissions data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/N2O.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Extract the data of interest**\n",
    "\n",
    "The original `df` contains records of N2O emissions from different countries throughout years. In this assignment, we will be interested in only the N2O emission from **the United States** throughout all the years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usa_N2O = df.loc[(df.Entity == 'United States')].loc[:, 'Total including LUCF (per capita)']\n",
    "usa_N2O = usa_N2O.to_numpy()\n",
    "year = df.loc[(df.Entity == 'United States')].loc[:, 'Year']\n",
    "year = year.to_numpy()\n",
    "np.mean(usa_N2O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. **Visualize the emission data from the United States throughout the years**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a plot to visualize the data\n",
    "_ = plt.plot(year, usa_N2O, marker = '.')\n",
    "#_ = plt.plot(year, world_N2O, marker = '.')\n",
    "_ = plt.xlabel('Year')\n",
    "_ = plt.ylabel('US Nitrous Oxide Emission')\n",
    "#_ = plt.legend([\"USA\"], loc =\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What questions do we want to ask?\n",
    "\n",
    "Often, you may already have some questions to ask before getting your data, or you may have some new questions after doing some exploratory data analysis. It's a good practice to clearly state your questions before starting the next step analysis. In the figure above, we can see that the nitrous oxide emission roughly follow a decreasing trend throughout the years. Today, our question will be:\n",
    "\n",
    "- Are the nitrous oxide emissions of United States after year 2005 different from those before 2005?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the question, let's create `usa_pre` and `usa_post` arrays that contains the yearly N2O emissions from the United States before and after year 2005. You will be working with these two sample arrays in the rest of this assignment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_pre = df.loc[(df.Entity == 'United States') & (df.Year <2005)].loc[:, 'Total including LUCF (per capita)']\n",
    "usa_pre = usa_pre.to_numpy()\n",
    "usa_post = df.loc[(df.Entity == 'United States') & (df.Year >= 2005)].loc[:, 'Total including LUCF (per capita)']\n",
    "usa_post = usa_post.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Bootstrap Confidence interval \n",
    "\n",
    "<br>\n",
    "\n",
    "**Question 1.** In this problem, you will explore the average N2O emissions of United States before and after year 2015 separately. You will work with 2 sample arrays: 1) `usa_pre`: yearly N2O emission data from the United States before year 2005, and 2) `usa_post`: yearly N2O emission data from the United States after year 2005. You will construct a $95\\%$ Bootstrap confidence interval for each of the two sample arrays using the `draw_bs_reps()` function you generated in the lecture exercise (Hint: You can call the function by `hast.draw_bs_reps(...)`). Follow the detailed instructions below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:**\n",
    "\n",
    "**(1).** print the means of `usa_pre` and `usa_post` in the cells below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2).** Use the `draw_bs_reps` function you created in the lecture exercises to generate 10000 means as Bootstrap replicates from `usa_pre` sample, and assign the results to `bs_usa_pre` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_usa_pre = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 95% confidence interval for `bs_usa_pre`\n",
    "np.percentile(____, ____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3).** Use the `draw_bs_reps` function you created in the lecture exercises to generate 10000 means as Bootstrap replicates from `usa_post` sample, and assign the results to `bs_usa_post` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_usa_post = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 95% confidence interval for `bs_usa_post`\n",
    "np.percentile(____, ____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4).** Interpretation of the two confidence intervals (Check the lecture notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Permutation test\n",
    "\n",
    "<br>\n",
    "\n",
    "**Question 2.** In this problem, you will test the null hypothesis: N2O emissions in the United States before and after 2005 are the same, using permutation test. You will again use the `usa_pre` and `usa_post` sample arrays. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**:\n",
    "\n",
    "**(1).** We will use the difference between means of the two arrays before and after 2005 as test statistic. Compute the observed test statistic using `mean_diff()` function you created in the lecture exercises (Hint: `mean_diff` function can be called by `hast.mean_diff(...)`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_diff = hast.mean_diff(usa_post, usa_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2).** Compute 10000 test statistics (again the difference between means) simulated from 10000 permutation samples using `draw_permutation_reps()` function you created in the lecture exercises (Hint: you can call the `draw_permutation_reps` function by `hast.draw_permutation_reps(...)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_replicates = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_replicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3).** Compute p-values: count the number of test-statistics as or more extreme than our initially observed test statistic, and divide that number by the total number of test-statistics we calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.sum(____ > observed_diff) / ____\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4).** Interpretation of the p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
