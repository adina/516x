{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is adapted from https://realpython.com/python-web-scraping-practical-introduction/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One useful package for web scraping that you can find in Python’s standard library is urllib, which contains tools for working with URLs. In particular, the urllib.request module contains a function called urlopen() that you can use to open a URL within a program.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web page that you’ll open is at the following URL:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://olympus.realpython.org/profiles/aphrodite\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can open the [URL](http://olympus.realpython.org/profiles/aphrodite) directly in your browser. You can open the page pass the content the urlopen with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " page = urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<http.client.HTTPResponse at 0x7faae6812c10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the HTML from the page, first use the HTTPResponse object’s .read() method, which returns a sequence of bytes. Then use .decode() to decode the bytes to a string using UTF-8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_bytes = page.read()\n",
    "html = html_bytes.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output that you’re seeing is the HTML code of the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>Profile: Aphrodite</title>\n",
      "</head>\n",
      "<body bgcolor=\"yellow\">\n",
      "<center>\n",
      "<br><br>\n",
      "<img src=\"/static/aphrodite.gif\" />\n",
      "<h2>Name: Aphrodite</h2>\n",
      "<br><br>\n",
      "Favorite animal: Dove\n",
      "<br><br>\n",
      "Favorite color: Red\n",
      "<br><br>\n",
      "Hometown: Mount Olympus\n",
      "</center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Text From HTML With String Methods\n",
    "One way to extract information from a web page’s HTML is to use string methods. For instance, you can use .find() to search through the text of the HTML for the <title> tags and extract the title of the web page.\n",
    "\n",
    "To start, you’ll extract the title of the web page that you requested in the previous example. If you know the index of the first character of the title and the index of the first character of the closing </title> tag, then you can use a string slice to extract the title.\n",
    "\n",
    "Because .find() returns the index of the first occurrence of a substring, you can get the index of the opening <title> tag by passing the string \"<title>\" to .find():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_index = html.find(\"<title>\")\n",
    "title_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don’t want the index of the title tag, though. You want the index of the title itself. To get the index of the first letter in the title, you can add the length of the string title to title_index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index = title_index + len(\"<title>\")\n",
    "start_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the index of the closing titletag by passing the string title to .find():\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_index = html.find(\"</title>\")\n",
    "end_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can extract the title by slicing the html string:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Profile: Aphrodite'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = html[start_index:end_index]\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real-world HTML can be much more complicated and far less predictable than the HTML on the Aphrodite profile page. Here’s another profile page with some messier HTML that you can scrape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<head>\\n<title >Profile: Poseidon'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://olympus.realpython.org/profiles/poseidon\"\n",
    "page = urlopen(url)\n",
    "html = page.read().decode(\"utf-8\")\n",
    "start_index = html.find(\"<title>\") + len(\"<title>\")\n",
    "end_index = html.find(\"</title>\")\n",
    "title = html[start_index:end_index]\n",
    "title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1\n",
    "\n",
    "Comment on why this is this happening and why this makes text scraping difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do a lot of scraping, it is worth learning about regular expressions and how to use them in Python.  This [tutorial](https://realpython.com/python-web-scraping-practical-introduction/) has some basic info but there are many other good tutorials you can find with googling python and regular expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://olympus.realpython.org/profiles/dionysus\"\n",
    "page = urlopen(url)\n",
    "html = page.read().decode(\"utf-8\")\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program does three things:\n",
    "\n",
    "Opens the URL http://olympus.realpython.org/profiles/dionysus by using urlopen() from the urllib.request module\n",
    "\n",
    "Reads the HTML from the page as a string and assigns it to the html variable\n",
    "\n",
    "Creates a BeautifulSoup object and assigns it to the soup variable\n",
    "\n",
    "The BeautifulSoup object assigned to soup is created with two arguments. The first argument is the HTML to be parsed, and the second argument, the string \"html.parser\", tells the object which parser to use behind the scenes. \"html.parser\" represents Python’s built-in HTML parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>Profile: Dionysus</title>\n",
       "</head>\n",
       "<body bgcolor=\"yellow\">\n",
       "<center>\n",
       "<br/><br/>\n",
       "<img src=\"/static/dionysus.jpg\"/>\n",
       "<h2>Name: Dionysus</h2>\n",
       "<img src=\"/static/grapes.png\"/><br/><br/>\n",
       "Hometown: Mount Olympus\n",
       "<br/><br/>\n",
       "Favorite animal: Leopard <br/>\n",
       "<br/>\n",
       "Favorite Color: Wine\n",
       "</center>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Profile: Dionysus\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Name: Dionysus\n",
      "\n",
      "Hometown: Mount Olympus\n",
      "\n",
      "Favorite animal: Leopard \n",
      "\n",
      "Favorite Color: Wine\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    " print(soup.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of blank lines in this output. These are the result of newline characters in the HTML document’s text. You can remove them with the .replace() string method if you need to.\n",
    "\n",
    "Often, you need to get only specific text from an HTML document. Using Beautiful Soup first to extract the text and then using the .find() string method is sometimes easier than working with regular expressions.\n",
    "\n",
    "However, other times the HTML tags themselves are the elements that point out the data you want to retrieve. For instance, perhaps you want to retrieve the URLs for all the images on the page. These links are contained in the src attribute of \"img\" HTML tags.\n",
    "\n",
    "In this case, you can use find_all() to return a list of all instances of that particular tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img src=\"/static/dionysus.jpg\"/>, <img src=\"/static/grapes.png\"/>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "his returns a list of all img tags in the HTML document. The objects in the list look like they might be strings representing the tags, but they’re actually instances of the Tag object provided by Beautiful Soup. Tag objects provide a simple interface for working with the information they contain.\n",
    "\n",
    "You can explore this a little by first unpacking the Tag objects from the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1, image2 = soup.find_all(\"img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the HTML attributes of the Tag object by putting their names between square brackets, just as if the attributes were keys in a dictionary. To get the source of the images in the Dionysus profile page, you access the src attribute using the dictionary notation mentioned above:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/static/dionysus.jpg'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1[\"src\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain tags in HTML documents can be accessed by properties of the Tag object. For example, to get the <title> tag in a document, you can use the .title property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Profile: Dionysus</title>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Profile: Dionysus'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2\n",
    "\n",
    "Write a program that grabs the full HTML from the page at the URL http://olympus.realpython.org/profiles.\n",
    "\n",
    "Using Beautiful Soup, print out a list of all the links on the page by looking for HTML tags with the name a and retrieving the value taken on by the href attribute of each tag.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 3\n",
    "\n",
    "Given that websites and their development are constantly changing, what might be challenges of writing sustainable code for text scraping?  What might you as someone who provides data do to provide a solution to these challenges?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API stands for application programming interface, which is a set of definitions and protocols for building and integrating application software. APIs let your product or service communicate with other products and services without having to know how they’re implemented. They also allow you to share your data with other external users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 4\n",
    "\n",
    "Identify 3 APIs that may provide data to users.  What types of data do they provide?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of an API:  openweathermap.org\n",
    "\n",
    "Imagine that you are trying to work with collecting data (or maybe even creating an application) where you ahve to obtain current, past, or forecasted weather for varying locations.\n",
    "\n",
    "One may use services of data repositories to collect this data.  One such service is OpenWeather.\n",
    "\n",
    "\"OpenWeather is a team of IT-intellectuals that create pivotal products for business using climate data. For each point on the globe, OpenWeather provides hyperlocal minutely forecast, historical data, current state, and from short-term to annual forecasted weather data.\"\n",
    "\n",
    "OpenWeather is an example of an API that provides data based on user-based queries.  In order to use it, you'll need to have an API \"key\".  Presently, to make sure you are not a \"bot\", most data queries are restricted to specific logins that have been validated.  OpenWeather does this by providing a \"key\" to their services once you've verified your email.  It also has multiple tiers of services provided by its API depending on your subscription.  \n",
    "\n",
    "In this class, we'll be working with the free subscription which limits the number of queries you are allowed and also the type of information provided (see this [link](https://openweathermap.org/price)).\n",
    "\n",
    "We are going to learn to use the API for the following:\n",
    "\n",
    "* Current Weather - https://openweathermap.org/current\n",
    "* 5 day weather forecasts - https://openweathermap.org/forecast5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APIs generally have a pattern to their text request, which comes in the form of a URL.  For OpenWeather's API, the beginning part of this request should start with the following:\n",
    "\n",
    "```\n",
    "https://api.openweathermap.org/data/2.5/weather?\n",
    "```\n",
    "\n",
    "Amended on the end of the url can be other terms that specify the information you are requesting:\n",
    "\n",
    "```\n",
    "https://api.openweathermap.org/data/2.5/weather?zip=50014&units=imperial\n",
    "```\n",
    "\n",
    "If you are to paste this URL into your browser, you'll get an error about needing a \"key\" for the API.  This requirement is becoming increasingly common to make any sort of requests to a server to ensure that you are not a 'bot'.  You should've registered for a key that is private to you in the last class.  This 'key' is alphanumberic text and can be amended at the end of your URL replacing {API KEY} below.\n",
    "\n",
    "```\n",
    "https://api.openweathermap.org/data/2.5/weather?zip=50014&units=imperial&appid={API KEY}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "\n",
    "Explore the documentation for finding current weather from OpenWeather.  Change the units and language of an API call for finding the current weather of your choice.  \n",
    "\n",
    "https://openweathermap.org/current\n",
    "\n",
    "Describe what kind of information you are getting back from your call.  Where is this information find in the API documentation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, you can use the 'requests' module to make a URL query, much like pasting a URL into a browser.  Within 'requests', you'll use the 'get' function.  This will store the information you obtain into a data object, 'resp'.  This data object has a number of attributes.  You can see the attributes of any python data object with the `dir` method.  You'll see in this case that `resp` has attributes like `raw` or `content` and can explore these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<urllib3.response.HTTPResponse object at 0x7fe4f76f3f90>\n",
      "b'{\"coord\":{\"lon\":-93.6945,\"lat\":42.0486},\"weather\":[{\"id\":800,\"main\":\"Clear\",\"description\":\"clear sky\",\"icon\":\"01d\"}],\"base\":\"stations\",\"main\":{\"temp\":32.81,\"feels_like\":25.14,\"temp_min\":29.97,\"temp_max\":37.89,\"pressure\":1017,\"humidity\":86},\"visibility\":10000,\"wind\":{\"speed\":9.22,\"deg\":140},\"clouds\":{\"all\":0},\"dt\":1673281345,\"sys\":{\"type\":2,\"id\":2041488,\"country\":\"US\",\"sunrise\":1673271745,\"sunset\":1673305249},\"timezone\":-21600,\"id\":0,\"name\":\"Ames\",\"cod\":200}'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = \"https://api.openweathermap.org/data/2.5/weather?zip=50014&units=imperial&appid=60d3c6c39ff016032e3271b5cb528e91\"\n",
    "resp = requests.get(url)\n",
    "dir(resp)\n",
    "print(resp.raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6\n",
    "\n",
    "What information is provided in the `resp.content`?\n",
    "\n",
    "This is in a specific format called JSON.  You can read about [JSON here](https://en.wikipedia.org/wiki/JSON).\n",
    " \n",
    "Print the JSON format of the `resp` data object using `resp.json`.\n",
    "Store the JSON format as a variable and explore it as Python dictionary. Print out the keys and values of the JSON format object.  Identify where these key and values are on the API documentation.\n",
    "\n",
    "Print out the temperature found within the 'main' output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7\n",
    "\n",
    "Pick 10 zipcodes to find the current weather.  Using API calls, store this information in a Pandas data table where you store the location, current temperature, minimum temperature, maximum temperature, and humidity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
